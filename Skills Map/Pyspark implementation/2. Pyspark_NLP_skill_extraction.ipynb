{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating spark context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pyspark script applies spark ML method on spark dataframes and RDD's. Unfortunately the function allowing to load the Google word2vec model is broken and was fixed only for (scala) spark. Nonetheless, we use a word2vec model trained on our data and match the corresponding vectors. Unfortunately results are less precise and the only merging algorithms that yield the same results as our python notebooks are for MinHashLSH or RandomBucketizedProjection. We tried those out but only obtained very poor results. As such we make this notebook available, which may save some time on preprocessing and vectorization but gives up the accuracy of the Google Word2Vec model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import findspark\n",
    "your_path = os.getcwd() # Path to spark if needed!\n",
    "findspark.init(your_path + 'spark-2.4.3-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark \n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(spark)\n",
    "sc = spark.sparkContext\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "from pyspark.sql import udf\n",
    "from pyspark.sql.types import StructType,StringType,StructField,FloatType\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, NGram, Word2Vec, HashingTF, MinHashLSH\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading spark dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Course schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['University', 'Program', 'Courses']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "courseSchema = StructType([ #StructField('index', StringType(), True),\n",
    "                           StructField('University', StringType(), True)\\\n",
    "                           ,StructField(\"Program\", StringType(), True)\\\n",
    "                           ,StructField(\"Courses\", StringType(), True)\\\n",
    "                           ,StructField(\"text\", StringType(), True)])\n",
    "\n",
    "courses_pd = pd.read_csv(\"proto1/universities_full.csv\",index_col = 0)\n",
    "courses = spark.createDataFrame(courses_pd,schema=courseSchema)\n",
    "\n",
    "#courses = (spark.read\n",
    "#    .schema(courseSchema)\n",
    "#    .option(\"header\", \"true\")\n",
    "#    .option(\"mode\", \"DROPMALFORMED\")\n",
    "#    .csv(\"proto1/universities_full.csv\"))\n",
    "['University',\"Program\",\"Courses\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skill schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "skillSchema = StructType([ #StructField('index', StringType(), True)\\,\n",
    "                          StructField(\"Skill\", StringType(), True)\\\n",
    "                          ,StructField(\"text\", StringType(), True)])\n",
    "#skillSchema = StructType([ StructField(\"text\", StringType(), True)])\n",
    "\n",
    "skills_pd = pd.read_csv(\"proto1/skills_full.csv\",index_col = 0)\n",
    "skills = spark.createDataFrame(skills_pd,schema=skillSchema)\n",
    "\n",
    "#skills = (spark.read\n",
    "#    .schema(skillSchema)\n",
    "#    .option(\"header\", \"true\")\n",
    "#    .option(\"mode\", \"DROPMALFORMED\")\n",
    "#    .csv(\"proto1/skills_full.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Occupation schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupationSchema = StructType([ StructField(\"Occupation\", StringType(), True)\\\n",
    "                               ,StructField(\"Skill\", StringType(), True)])\n",
    "\n",
    "occupations_pd = pd.read_csv('proto1/occupations_full.csv')\n",
    "occupations = spark.createDataFrame(occupations_pd,schema=occupationSchema)\n",
    "\n",
    "\n",
    "#occupations = (spark.read\n",
    "#    .schema(occupationSchema)\n",
    "#    .option(\"header\", \"true\")\n",
    "#    .option(\"mode\", \"DROPMALFORMED\")\n",
    "#    .csv(\"proto1/occupations_full.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining pipeline for string similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining stopwords for pre-processing (faster than loading from nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopW = ['i','me','my', 'myself','we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours',\n",
    " 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
    " 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these',\n",
    " 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did',\n",
    " 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about',\n",
    " 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in',\n",
    " 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how',\n",
    " 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same',\n",
    " 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm',\n",
    " 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\",\n",
    " 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan',\n",
    " \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\",\"pdf\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "course = courses.select(\"text\").toDF(\"text\").filter(col('text').isNotNull())\n",
    "skill = skills.select(\"text\").toDF(\"text\").filter(col('text').isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec trained on course strings\n",
    "model = Pipeline(stages=[\n",
    "    RegexTokenizer(gaps = False, pattern = '\\w+', inputCol = 'text', outputCol = 'tokens'),\n",
    "    StopWordsRemover(stopWords = stopW, inputCol = 'tokens', outputCol = 'tokens_sw'),\n",
    "    #NGram(n=2, inputCol=\"tokens_sw\", outputCol=\"ngrams\"),\n",
    "    Word2Vec(vectorSize = 300, minCount = 2, inputCol = 'tokens_sw',outputCol = 'vectors')\n",
    "]).fit(course)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating columns defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_hashed = model.transform(course)\n",
    "skill_hashed = model.transform(skill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining cosine similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cossim(v1, v2): \n",
    "    return  np.absolute(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tranforming transformed dataframes to rdd  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_test1 = course_hashed.count()\n",
    "length_test2 = skill_hashed.count()\n",
    "test1 = course_hashed.select(\"vectors\").rdd\n",
    "test2 = skill_hashed.select(\"vectors\").rdd\n",
    "test1.cache()\n",
    "test2.cache()\n",
    "test3 = test1.collect()\n",
    "test4 = test2.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas inefficient matching..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(columns = ['University',\"Program\",\"Courses\",\"Skills\",'Similarity'])\n",
    "l = 0\n",
    "\n",
    "for i in range(0,length_test1): \n",
    "    for j in range(0,length_test2): \n",
    "        if np.linalg.norm(test3[i][0]) != 0 and np.linalg.norm(test4[j][0]) != 0:\n",
    "            score = cossim(test3[i][0],test4[j][0])\n",
    "            if score > 0.65:\n",
    "                temp.loc[l,['University',\"Program\",\"Courses\"]] = courses_pd.loc[i,['University',\"Program\",\"Courses\"]]\n",
    "                temp.loc[l,'Skills'] = skills_pd.loc[j,'Skill']\n",
    "                temp.loc[l,'Similarity'] = score\n",
    "                l += 1\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.to_csv('NLP_results_proto1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('NLP_results_proto1.csv',index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>University</th>\n",
       "      <th>Program</th>\n",
       "      <th>Courses</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149187</th>\n",
       "      <td>Free University of Brussels</td>\n",
       "      <td>Master of Economics of Globalisation and Europ...</td>\n",
       "      <td>Academic Writing</td>\n",
       "      <td>use specific writing techniques</td>\n",
       "      <td>0.660128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149188</th>\n",
       "      <td>Free University of Brussels</td>\n",
       "      <td>Master of Economics of Globalisation and Europ...</td>\n",
       "      <td>Academic Writing</td>\n",
       "      <td>report analysis results</td>\n",
       "      <td>0.697671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149189</th>\n",
       "      <td>Free University of Brussels</td>\n",
       "      <td>Master of Economics of Globalisation and Europ...</td>\n",
       "      <td>Academic Writing</td>\n",
       "      <td>study relevant writing</td>\n",
       "      <td>0.693779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149190</th>\n",
       "      <td>Free University of Brussels</td>\n",
       "      <td>Master of Economics of Globalisation and Europ...</td>\n",
       "      <td>Academic Writing</td>\n",
       "      <td>scientific research methodology</td>\n",
       "      <td>0.677442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149191</th>\n",
       "      <td>Free University of Brussels</td>\n",
       "      <td>Master of Economics of Globalisation and Europ...</td>\n",
       "      <td>Academic Writing</td>\n",
       "      <td>perform background research on writing subject</td>\n",
       "      <td>0.689483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         University  \\\n",
       "149187  Free University of Brussels   \n",
       "149188  Free University of Brussels   \n",
       "149189  Free University of Brussels   \n",
       "149190  Free University of Brussels   \n",
       "149191  Free University of Brussels   \n",
       "\n",
       "                                                  Program           Courses  \\\n",
       "149187  Master of Economics of Globalisation and Europ...  Academic Writing   \n",
       "149188  Master of Economics of Globalisation and Europ...  Academic Writing   \n",
       "149189  Master of Economics of Globalisation and Europ...  Academic Writing   \n",
       "149190  Master of Economics of Globalisation and Europ...  Academic Writing   \n",
       "149191  Master of Economics of Globalisation and Europ...  Academic Writing   \n",
       "\n",
       "                                                Skills  Similarity  \n",
       "149187                 use specific writing techniques    0.660128  \n",
       "149188                         report analysis results    0.697671  \n",
       "149189                          study relevant writing    0.693779  \n",
       "149190                 scientific research methodology    0.677442  \n",
       "149191  perform background research on writing subject    0.689483  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
